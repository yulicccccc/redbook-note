import streamlit as st
import google.generativeai as genai
import gspread
import json
import pandas as pd
import re
from datetime import datetime
from PIL import Image

# --- 1. é¡µé¢é…ç½® ---
st.set_page_config(page_title="Kiraçš„å¤§è„‘å¤–æŒ‚", layout="centered", page_icon="ğŸ§ ")

# --- 2. åˆå§‹åŒ– ---
if "messages" not in st.session_state:
    st.session_state.messages = []
if "analysis_result" not in st.session_state:
    st.session_state.analysis_result = None
if "raw_content" not in st.session_state:
    st.session_state.raw_content = ""

# --- 3. è¿æ¥ Google Sheets ---
@st.cache_resource
def connect_to_sheet():
    try:
        if "gcp_json" in st.secrets:
            creds = json.loads(st.secrets["gcp_json"])
            gc = gspread.service_account_from_dict(creds)
            return gc.open("My_Knowledge_Base").sheet1
        return None
    except:
        return None

# --- 4. ä¾§è¾¹æ  ---
with st.sidebar:
    st.title("âš™ï¸ è®¾ç½®")
    api_key = st.text_input("Gemini API Key", type="password")
    st.divider()
    if st.button("ğŸ“š ç”Ÿæˆæœ¬å‘¨å¤ä¹ æ–‡æœ¬"):
        sheet = connect_to_sheet()
        if sheet:
            df = pd.DataFrame(sheet.get_all_records())
            if not df.empty:
                text = "# æœ¬å‘¨çŸ¥è¯†æ±‡æ€»\n\n" + df.tail(15).to_string()
                st.code(text, language="markdown")

# --- 5. ä¸»ç¨‹åº ---
st.title("ğŸ§  Kira's Brain Extension")
st.caption("å…¼å®¹æ¨¡å¼ | è‡ªåŠ¨åˆ‡æ¢ Pro/Vision")

if not api_key:
    st.warning("ğŸ‘ˆ è¯·å…ˆè¾“å…¥ API Key")
    st.stop()

genai.configure(api_key=api_key)

# ==========================================
# ğŸ§  æ ¸å¿ƒï¼šæ™ºèƒ½å…¼å®¹å‡½æ•° (è§£å†³ 404 çš„å…³é”®)
# ==========================================
def get_safe_response(prompt_text, image_obj=None):
    """
    æ—¢ç„¶ Flash ç”¨ä¸äº†ï¼Œæˆ‘ä»¬å°±ç”¨è€æ¨¡å‹ã€‚
    æœ‰å›¾ -> gemini-pro-vision
    æ— å›¾ -> gemini-pro
    """
    try:
        if image_obj:
            # === è§†è§‰æ¨¡å¼ ===
            model = genai.GenerativeModel('gemini-pro-vision')
            # è€ç‰ˆè§†è§‰æ¨¡å‹è¦æ±‚ List æ ¼å¼: [Prompt, Image]
            response = model.generate_content([prompt_text, image_obj])
        else:
            # === çº¯æ–‡å­—æ¨¡å¼ ===
            model = genai.GenerativeModel('gemini-pro')
            response = model.generate_content(prompt_text)
        return response.text
    except Exception as e:
        return f"Error: {str(e)}"

# ==========================================
# ä¸ŠåŠåœºï¼šåˆ†æåŒº
# ==========================================
st.header("1. å–‚å…¥ç´ æ", divider="rainbow")

content_text = st.text_area("ğŸ“ ç²˜è´´å†…å®¹ï¼š", height=100)
uploaded_file = st.file_uploader("ğŸ“¸ ä¸Šä¼ æˆªå›¾", type=["jpg", "png", "webp"])

if st.button("âœ¨ å¯åŠ¨å¤§è„‘è§£æ", type="primary", use_container_width=True):
    if not content_text and not uploaded_file:
        st.warning("ç»™ç‚¹ä¸œè¥¿åˆ†æå‘—ï¼")
    else:
        with st.spinner("ğŸ§  æ­£åœ¨è°ƒç”¨å…¼å®¹æ¨¡å‹å¼•æ“..."):
            # å‡†å¤‡æ•°æ®
            img = None
            display_content = content_text if content_text else ""
            if uploaded_file:
                img = Image.open(uploaded_file)
                display_content += " [å›¾ç‰‡]"
            
            st.session_state.raw_content = display_content

            # Prompt
            base_prompt = """
            ä½ æ˜¯ä¸€ä¸ªæ‡‚ ADHD çš„é«˜çº§çŸ¥è¯†ä¼™ä¼´ã€‚è¯·å¯¹è¾“å…¥å†…å®¹è§£æï¼š
            ã€Part 1: æ·±åº¦å¡ç‰‡ã€‘(ä¸“å®¶è§†è§’ï¼Œä¿æŒ PhD çº§çš„æ·±åº¦)
            1. **è‡ªåŠ¨åˆ†ç±»**ï¼šå¿…é¡»ä» [è·³èˆ, åˆ›æ„æ‘„åƒ, è‹±è¯­, AIåº”ç”¨, äººæƒ…ä¸–æ•…, å­¦ä¹ ä¸ä¸ªäººæˆé•¿, å…¶ä»–çµæ„Ÿ] é€‰ä¸€ã€‚
            2. **æ ¸å¿ƒé€»è¾‘**ï¼š3 ä¸ª bullet points æç‚¼æœ€æœ‰ä»·å€¼ä¿¡æ¯ã€‚
            3. **ä¸“å®¶å»ºè®®**ï¼šæ·±åº¦ã€é•¿è¿œè§†è§’çš„æ´å¯Ÿã€‚

            ã€Part 2: æç®€è¡ŒåŠ¨ã€‘(ADHD æ•™ç»ƒè§†è§’)
            ç”Ÿæˆ **æœ€å¤š 3 ä¸ª** åŸå­çº§ Action Items (1åˆ†é’Ÿèƒ½å¼€å§‹)ã€‚
            æ ¼å¼ï¼šè¯·ä¸¥æ ¼æŠŠä»»åŠ¡æ”¾åœ¨ ---ACTION_START--- å’Œ ---ACTION_END--- ä¹‹é—´ï¼Œæ¯è¡Œä¸€ä¸ªã€‚
            
            å†…å®¹å¦‚ä¸‹ï¼š
            """
            
            # è°ƒç”¨å…¼å®¹å‡½æ•°
            full_res = get_safe_response(base_prompt + "\n" + content_text, img)

            # é”™è¯¯å¤„ç†
            if "Error:" in full_res:
                st.error("å‡ºé”™å•¦ï¼š" + full_res)
            else:
                # è§£ææˆåŠŸ
                main_analysis = full_res.split("---ACTION_START---")[0].strip()
                action_part = re.search(r"---ACTION_START---(.*)---ACTION_END---", full_res, re.DOTALL)
                
                st.session_state.analysis_result = main_analysis
                
                # æå–åˆ†ç±»
                st.session_state.temp_tag = "å…¶ä»–çµæ„Ÿ"
                for tag in ["è·³èˆ", "åˆ›æ„æ‘„åƒ", "è‹±è¯­", "AIåº”ç”¨", "äººæƒ…ä¸–æ•…", "å­¦ä¹ ä¸ä¸ªäººæˆé•¿"]:
                    if tag in main_analysis:
                        st.session_state.temp_tag = tag
                        break

                # æå–ä»»åŠ¡
                if action_part:
                    tasks = [t.strip() for t in action_part.group(1).strip().split('\n') if t.strip()]
                    clean_tasks = [re.sub(r'^\d+\.\s*', '', t).replace('- [ ]', '').strip() for t in tasks]
                    st.session_state.todo_df = pd.DataFrame([{"Done": False, "Task": t} for t in clean_tasks])
                else:
                    st.session_state.todo_df = pd.DataFrame([{"Done": False, "Task": "é˜…åå³ç„š"}])
                
                # åˆå§‹åŒ–èŠå¤© (åªå­˜æ–‡æœ¬ï¼Œå› ä¸ºè€ç‰ˆ Pro ä¸æ”¯æŒå¤šè½®å›¾ç‰‡å†å²)
                st.session_state.messages = []
                st.session_state.messages.append({"role": "user", "content": f"ç´ æï¼š{display_content}"})
                st.session_state.messages.append({"role": "assistant", "content": full_res})

# ==========================================
# ç»“æœä¸å­˜æ¡£
# ==========================================
if st.session_state.analysis_result:
    st.divider()
    st.header("2. ç¡®è®¤ä¸è¡ŒåŠ¨", divider="violet")
    
    st.info(f"ğŸ“‚ åˆ†ç±»ï¼š{st.session_state.get('temp_tag', 'æœªåˆ†ç±»')}")
    st.markdown(st.session_state.analysis_result)
    
    st.subheader("âœ… æç®€æ¸…å•")
    edited_df = st.data_editor(st.session_state.todo_df, num_rows="dynamic", use_container_width=True)
    
    user_thought = st.text_area("ğŸ’­ æ­¤æ—¶çš„æƒ³æ³•:", height=80)
    
    if st.button("ğŸ’¾ å­˜å…¥çŸ¥è¯†åº“", type="primary", use_container_width=True):
        sheet = connect_to_sheet()
        if sheet:
            try:
                final_actions = []
                for index, row in edited_df.iterrows():
                    t = row['Task']
                    if row['Done']: t = "".join([u'\u0336' + char for char in t]) + " âœ…"
                    final_actions.append(f"{index+1}. {t}")
                action_str = "\n".join(final_actions)
                date_str = datetime.now().strftime("%Y-%m-%d")
                
                sheet.append_row([
                    date_str, st.session_state.temp_tag, user_thought, 
                    action_str, st.session_state.analysis_result, 
                    st.session_state.get("raw_content", "")
                ])
                st.success("ğŸ‰ å·²å­˜å…¥ï¼")
            except Exception as e:
                st.error(f"å†™å…¥å¤±è´¥: {e}")

    # ==========================================
    # ä¸‹åŠåœºï¼šèŠå¤©æŒ‚ä»¶ (å¼ºåˆ¶æ–‡æœ¬æ¨¡å¼)
    # ==========================================
    st.divider()
    with st.expander("ğŸ’¬ è¿½é—® (çº¯æ–‡æœ¬æ¨¡å¼)", expanded=False):
        for i, msg in enumerate(st.session_state.messages):
            if i > 0: # ç¨å¾®éšè—ä¸‹å¤æ‚çš„åˆå§‹Prompt
                with st.chat_message(msg["role"]): st.markdown(msg["content"])
        
        if chat_input := st.chat_input("è¿½é—®..."):
            with st.chat_message("user"): st.markdown(chat_input)
            st.session_state.messages.append({"role": "user", "content": chat_input})
            
            # ä½¿ç”¨è€ç‰ˆ Pro è¿›è¡Œå¯¹è¯ (ä¸å¸¦å›¾)
            model = genai.GenerativeModel('gemini-pro')
            
            # æ‹¼æ¥å†å²æ–‡æœ¬ (è€ç‰ˆSDKæœ€ç¨³å¦¥åšæ³•)
            full_context = ""
            for m in st.session_state.messages:
                full_context += f"{m['role']}: {m['content']}\n"
            
            with st.chat_message("assistant"):
                with st.spinner("Thinking..."):
                    try:
                        response = model.generate_content(full_context)
                        st.markdown(response.text)
                        st.session_state.messages.append({"role": "assistant", "content": response.text})
                    except Exception as e:
                        st.error(f"èŠå¤©å‡ºé”™: {e}")
