import streamlit as st
import google.generativeai as genai
import gspread
import json
import pandas as pd
import re
from datetime import datetime
from PIL import Image

# --- 1. é¡µé¢é…ç½® ---
st.set_page_config(page_title="Kiraçš„å¤§è„‘å¤–æŒ‚", layout="centered", page_icon="ğŸ§ ")

# --- 2. åˆå§‹åŒ– ---
if "messages" not in st.session_state:
    st.session_state.messages = []
if "analysis_result" not in st.session_state:
    st.session_state.analysis_result = None
if "raw_content" not in st.session_state:
    st.session_state.raw_content = ""

# --- 3. è¿æ¥ Google Sheets ---
@st.cache_resource
def connect_to_sheet():
    try:
        if "gcp_json" in st.secrets:
            creds = json.loads(st.secrets["gcp_json"])
            gc = gspread.service_account_from_dict(creds)
            return gc.open("My_Knowledge_Base").sheet1
        return None
    except:
        return None

# --- 4. ä¾§è¾¹æ  ---
with st.sidebar:
    st.title("âš™ï¸ è®¾ç½®")
    api_key = st.text_input("Gemini API Key", type="password")
    
    st.divider()
    if st.button("ğŸ“š ç”Ÿæˆæœ¬å‘¨å¤ä¹ æ–‡æœ¬"):
        sheet = connect_to_sheet()
        if sheet:
            df = pd.DataFrame(sheet.get_all_records())
            if not df.empty:
                text = "# æœ¬å‘¨çŸ¥è¯†æ±‡æ€»\n\n" + df.tail(15).to_string()
                st.code(text, language="markdown")

# --- 5. ä¸»ç¨‹åº ---
st.title("ğŸ§  Kira's Brain Extension")
st.caption("ğŸš€ é€‚é…ç‰ˆ | ä½¿ç”¨ Gemini 2.0 Flash")

if not api_key:
    st.warning("ğŸ‘ˆ è¯·å…ˆè¾“å…¥ API Key")
    st.stop()

genai.configure(api_key=api_key)

# ğŸŒŸ å…³é”®ä¿®æ”¹ï¼šæ ¹æ®ä½ çš„è¯Šæ–­åˆ—è¡¨ï¼Œä½¿ç”¨å­˜åœ¨çš„ 'gemini-2.0-flash' ğŸŒŸ
# å¦‚æœ 2.0 é‡åˆ°é™æµï¼Œä»£ç ä¼šè‡ªåŠ¨æç¤º
target_model_name = 'gemini-2.0-flash' 
model = genai.GenerativeModel(target_model_name)

# ==========================================
# æ ¸å¿ƒåŠŸèƒ½åŒº
# ==========================================
st.header("1. å–‚å…¥ç´ æ", divider="rainbow")

content_text = st.text_area("ğŸ“ ç²˜è´´å†…å®¹ï¼š", height=100)
uploaded_file = st.file_uploader("ğŸ“¸ ä¸Šä¼ æˆªå›¾", type=["jpg", "png", "webp"])

if st.button("âœ¨ å¯åŠ¨å¤§è„‘è§£æ", type="primary", use_container_width=True):
    if not content_text and not uploaded_file:
        st.warning("è¯·æä¾›å†…å®¹ï¼")
    else:
        with st.spinner(f"ğŸ§  æ­£åœ¨è°ƒç”¨ {target_model_name} ..."):
            try:
                # 1. å‡†å¤‡è¾“å…¥
                inputs = []
                display_content = content_text if content_text else ""
                if content_text: inputs.append(content_text)
                if uploaded_file:
                    img = Image.open(uploaded_file)
                    inputs.append(img)
                    display_content += " [å›¾ç‰‡]"
                
                st.session_state.raw_content = display_content

                # 2. æ ¸å¿ƒ Prompt
                prompt = """
                ä½ æ˜¯ä¸€ä¸ªæ‡‚ ADHD çš„é«˜çº§çŸ¥è¯†ä¼™ä¼´ã€‚è¯·å¯¹è¾“å…¥å†…å®¹è§£æï¼š
                ã€Part 1: æ·±åº¦å¡ç‰‡ã€‘(ä¸“å®¶è§†è§’ï¼Œä¿æŒ PhD çº§çš„æ·±åº¦)
                1. **è‡ªåŠ¨åˆ†ç±»**ï¼šå¿…é¡»ä» [è·³èˆ, åˆ›æ„æ‘„åƒ, è‹±è¯­, AIåº”ç”¨, äººæƒ…ä¸–æ•…, å­¦ä¹ ä¸ä¸ªäººæˆé•¿, å…¶ä»–çµæ„Ÿ] é€‰ä¸€ã€‚
                2. **æ ¸å¿ƒé€»è¾‘**ï¼š3 ä¸ª bullet points æç‚¼æœ€æœ‰ä»·å€¼ä¿¡æ¯ï¼ˆå¦‚æœæ˜¯å›¾ï¼Œåˆ†ææ„å›¾/è‰²å½©/åŠ¨ä½œï¼‰ã€‚
                3. **ä¸“å®¶å»ºè®®**ï¼šæ·±åº¦ã€é•¿è¿œè§†è§’çš„æ´å¯Ÿã€‚

                ã€Part 2: æç®€è¡ŒåŠ¨ã€‘(ADHD æ•™ç»ƒè§†è§’)
                ç”Ÿæˆ **æœ€å¤š 3 ä¸ª** åŸå­çº§ Action Items (1åˆ†é’Ÿèƒ½å¼€å§‹)ã€‚
                æ ¼å¼ï¼šè¯·ä¸¥æ ¼æŠŠä»»åŠ¡æ”¾åœ¨ ---ACTION_START--- å’Œ ---ACTION_END--- ä¹‹é—´ï¼Œæ¯è¡Œä¸€ä¸ªã€‚
                """
                inputs.append(prompt)

                # 3. è°ƒç”¨ API
                response = model.generate_content(inputs)
                full_res = response.text
                
                # 4. è§£æç»“æœ
                main_analysis = full_res.split("---ACTION_START---")[0].strip()
                action_part = re.search(r"---ACTION_START---(.*)---ACTION_END---", full_res, re.DOTALL)
                
                st.session_state.analysis_result = main_analysis
                
                # æå–åˆ†ç±»
                st.session_state.temp_tag = "å…¶ä»–çµæ„Ÿ"
                for tag in ["è·³èˆ", "åˆ›æ„æ‘„åƒ", "è‹±è¯­", "AIåº”ç”¨", "äººæƒ…ä¸–æ•…", "å­¦ä¹ ä¸ä¸ªäººæˆé•¿"]:
                    if tag in main_analysis:
                        st.session_state.temp_tag = tag
                        break

                # æå–ä»»åŠ¡
                if action_part:
                    tasks = [t.strip() for t in action_part.group(1).strip().split('\n') if t.strip()]
                    clean_tasks = [re.sub(r'^\d+\.\s*', '', t).replace('- [ ]', '').strip() for t in tasks]
                    st.session_state.todo_df = pd.DataFrame([{"Done": False, "Task": t} for t in clean_tasks])
                else:
                    st.session_state.todo_df = pd.DataFrame([{"Done": False, "Task": "é˜…åå³ç„š"}])
                
                # åˆå§‹åŒ–èŠå¤©
                st.session_state.messages = []
                st.session_state.messages.append({"role": "user", "content": f"ç´ æï¼š{display_content}"})
                st.session_state.messages.append({"role": "assistant", "content": full_res})

            except Exception as e:
                # é”™è¯¯å¤„ç†
                err_msg = str(e)
                if "429" in err_msg:
                    st.error(f"âŒ é€Ÿåº¦å¤ªå¿«è¢«é™æµäº†ï¼Gemini 2.0 æ¯”è¾ƒæŠ¢æ‰‹ã€‚è¯·ç­‰ 1 åˆ†é’Ÿå†è¯•ã€‚")
                elif "404" in err_msg:
                    st.error(f"âŒ æ‰¾ä¸åˆ°æ¨¡å‹ {target_model_name}ã€‚è¯·æ£€æŸ¥ API Key æƒé™ã€‚")
                else:
                    st.error(f"è§£æå¤±è´¥: {e}")

# ==========================================
# ç»“æœä¸å­˜æ¡£
# ==========================================
if st.session_state.analysis_result:
    st.divider()
    st.header("2. ç¡®è®¤ä¸è¡ŒåŠ¨", divider="violet")
    
    st.info(f"ğŸ“‚ åˆ†ç±»ï¼š{st.session_state.get('temp_tag', 'æœªåˆ†ç±»')}")
    st.markdown(st.session_state.analysis_result)
    
    st.subheader("âœ… æç®€æ¸…å•")
    edited_df = st.data_editor(st.session_state.todo_df, num_rows="dynamic", use_container_width=True)
    
    user_thought = st.text_area("ğŸ’­ æ­¤æ—¶çš„æƒ³æ³•:", height=80)
    
    if st.button("ğŸ’¾ å­˜å…¥çŸ¥è¯†åº“", type="primary", use_container_width=True):
        sheet = connect_to_sheet()
        if sheet:
            try:
                final_actions = []
                for index, row in edited_df.iterrows():
                    t = row['Task']
                    if row['Done']: t = "".join([u'\u0336' + char for char in t]) + " âœ…"
                    final_actions.append(f"{index+1}. {t}")
                action_str = "\n".join(final_actions)
                date_str = datetime.now().strftime("%Y-%m-%d")
                
                sheet.append_row([
                    date_str, st.session_state.temp_tag, user_thought, 
                    action_str, st.session_state.analysis_result, 
                    st.session_state.get("raw_content", "")
                ])
                st.success("ğŸ‰ å·²å­˜å…¥ï¼")
            except Exception as e:
                st.error(f"å†™å…¥å¤±è´¥: {e}")

    # ==========================================
    # èŠå¤©æŒ‚ä»¶
    # ==========================================
    st.divider()
    with st.expander("ğŸ’¬ è¿½é—®", expanded=False):
        for i, msg in enumerate(st.session_state.messages):
            if i > 0:
                with st.chat_message(msg["role"]): st.markdown(msg["content"])
        
        if chat_input := st.chat_input("è¿½é—®..."):
            with st.chat_message("user"): st.markdown(chat_input)
            st.session_state.messages.append({"role": "user", "content": chat_input})
            
            # ä½¿ç”¨åŒæ ·çš„ 2.0 Flash è¿›è¡Œå¯¹è¯
            model = genai.GenerativeModel(target_model_name)
            
            # ç®€å•å¤„ç†å†å²ï¼ˆåªä¼ æ–‡æœ¬ï¼‰
            history_text = []
            for m in st.session_state.messages:
                 history_text.append({"role": "user" if m["role"]=="user" else "model", "parts": [str(m["content"])]})

            with st.chat_message("assistant"):
                with st.spinner("Thinking..."):
                    try:
                        chat = model.start_chat(history=history_text[:-1])
                        response = chat.send_message(chat_input)
                        st.markdown(response.text)
                        st.session_state.messages.append({"role": "assistant", "content": response.text})
                    except Exception as e:
                        st.error(f"èŠå¤©å‡ºé”™: {e}")
